{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task in computational research is to classify an object based on a set of features. In superivsed machine learning, we can give an algorithm a dataset of training examples that say \"here are specific features, and this is the class it belongs to\". With enough training examples, a model can be built that recognizes important features in determining an objects class. This model can then be used to predict the class of an object given its known features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by loading scikit-learn's [Iris](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) dataset. Using this dataset we can classify an iris flower as one of three types: setosa, versicolour, or virginica. The features that we'll use to predict this are sepal length, sepal width, petal length, and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside of it to see what datatypes scikit-learn wants, and how their sample dataset is formatted, so that we can prepare our own datasets later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data is in dictionary format, and we can access the data and labels by indexing certain keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here are the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(iris.feature_names)\n",
    "print(len(iris.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what we're predicting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(iris.target_names)\n",
    "print(len(iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are using 4 features for each observation, trying to classfiy each observation into one of three categories, using only those 4 features. How are these input features formatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(iris.data))\n",
    "print(type(iris.data))\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a large numpy array of length 150, one for each observation, and each observation has its own numpy array of length 4, one for each feature. Each inner array *must* lineup with the order of the variables *and* all other arrays. **ORDER MATTERS**.\n",
    "\n",
    "What about the prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(iris.target))\n",
    "print(type(iris.target))\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have 150 observations, but *no* sub arrays. The target data is one dimension. Order matters here as well, they should correspond to the feature indices in the data array. These are the correct class corresponding to the data arrays.\n",
    "\n",
    "In other words, the data and the targets should match up like this for three of the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in [0, 50, 100]:\n",
    "    print(\"Data:\", iris.data[x])\n",
    "    print(\"Target:\", iris.target[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be enough explanation to be able to get your own data from CSV or other formats into the correct numpy arryays for scikit-learn.\n",
    "\n",
    "Now we split the data into training and testing, but first thing's first: **set the random seed!**. This is very important for reproducibility of your analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use 75% of the data for training, and test on the remaining 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we're going to explore is [Decision Trees](http://scikit-learn.org/stable/modules/tree.html).\n",
    "\n",
    "After the train/test split, scikit-learn makes the rest of the process relatively easy, since it already has a DT classifier algorith for us, we just have to decide on the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt_classifier = tree.DecisionTreeClassifier(criterion='gini',  # or 'entropy' for information gain\n",
    "                       splitter='best',  # or 'random' for random best split\n",
    "                       max_depth=None,  # how deep tree nodes can go\n",
    "                       min_samples_split=2,  # samples needed to split node\n",
    "                       min_samples_leaf=1,  # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,  # weight of samples needed for a node\n",
    "                       max_features=None,  # number of features to look for when splitting\n",
    "                       max_leaf_nodes=None,  # max nodes\n",
    "                       min_impurity_split=1e-07, #early stopping\n",
    "                       random_state = 10) #random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `fit` method on the train data to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how our model performs on the test data, we use the `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning parameters is one of the most important steps in building a ML model. One way to do this is by using what's called a [grid search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). A grid search tests different possible parameter combinations to see which combination yields the best results. Fortunately, scikit-learn has a function for this which makes it very easy to do.\n",
    "\n",
    "Here we'll see what the best combination of the parameters `min_samples_split` and `min_samples_leaf` is. We can make a dictionary with the names of the parameters as the keys and the range of values as the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_split': range(2,10),\n",
    "              'min_samples_leaf': range(1,10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can implement the grid search and fit our model according to the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_c = GridSearchCV(tree.DecisionTreeClassifier(), param_grid)\n",
    "model_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the best parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_index = np.argmax(model_c.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(model_c.cv_results_[\"params\"][best_index])\n",
    "print(max(model_c.cv_results_[\"mean_test_score\"]))\n",
    "print(model_c.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at all of the combinations and their test and train scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_c.cv_results_.keys()\n",
    "\n",
    "for x in range(len(model_c.cv_results_['params'])):\n",
    "    print(\"Parameters:\")\n",
    "    print(model_c.cv_results_['params'][x])\n",
    "    print(\"Mean Test Score:\")\n",
    "    print(model_c.cv_results_['mean_test_score'][x])\n",
    "    print(\"Mean Train Score:\")\n",
    "    print(model_c.cv_results_['mean_train_score'][x])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at [Random Forests](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators=10,  # number of trees\n",
    "                       criterion='gini',  # or 'entropy' for information gain\n",
    "                       max_depth=None,  # how deep tree nodes can go\n",
    "                       min_samples_split=2,  # samples needed to split node\n",
    "                       min_samples_leaf=1,  # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,  # weight of samples needed for a node\n",
    "                       max_features='auto',  # number of features for best split\n",
    "                       max_leaf_nodes=None,  # max nodes\n",
    "                       min_impurity_split=1e-07,  # early stopping\n",
    "                       n_jobs=1,  # CPUs to use\n",
    "                       random_state = 10,  # random seed\n",
    "                       class_weight=\"balanced\")  # adjusts weights inverse of freq, also \"balanced_subsample\" or None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Score of model with test data defined above:\")\n",
    "print(model.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, predicted)) \n",
    "print()\n",
    "\n",
    "scores = cross_val_score(model, iris.data, iris.target, cv=10)\n",
    "print(\"10-fold cross-validation:\")\n",
    "print(scores)\n",
    "print()\n",
    "\n",
    "print(\"Average of 10-fold cross-validation:\")\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another grid search to determine the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_split': range(2,10),\n",
    "              'min_samples_leaf': range(1,10)}\n",
    "\n",
    "model_r = GridSearchCV(ensemble.RandomForestClassifier(), param_grid)\n",
    "model_r.fit(X_train, y_train)\n",
    "\n",
    "best_index = np.argmax(model_r.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "print(\"Best index:\", model_r.cv_results_[\"params\"][best_index])\n",
    "print(\"Mean test score:\", max(model_r.cv_results_[\"mean_test_score\"]))\n",
    "print(\"Held-out:\", model_r.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Using the scikit-learn [documentation](http://scikit-learn.org/stable/modules/ensemble.html#adaboost), build your own AdaBoost model to test on the iris data set! Start off with `n_estimators` at 100, and `learning_rate` at .5. Use 10 as the `random_state` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Now use a grid search to determine what the best values for the `n_estimators` and `learning_rate` parameters are. For `n_estimators` try a range of 50 to 500 with a step of 50, and for `learning_rate` try a range of .1 to 1.1 with a step of .1. For decimal steps in a range use the `np.arange` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
